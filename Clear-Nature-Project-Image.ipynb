{"cells":[{"cell_type":"markdown","metadata":{"id":"qUxDWppscBQF"},"source":["# This is the Clear Nature project notebook of Amir Grossman and Maya Attia from the Technion's ECE faculty."]},{"cell_type":"markdown","source":["Detectron2 + simple-lama-inpainting: \\\n","Much more easy to run than previous version.\\\n","at first we got good masks from detectron, but the inpainting was pretty bad, beside a few picters with small-area people.\\\n","We added dilation to increase mask size to improve inpainting and to avoid small misses in mask generation."],"metadata":{"id":"zetHpo4j8SXG"}},{"cell_type":"code","source":["# Step 0: Install and setup dependencies\n","!pip install -q git+https://github.com/facebookresearch/detectron2.git opencv-python matplotlib gdown omegaconf einops pytorch_lightning\n","!pip install -q simple_lama_inpainting\n","\n","!rm -rf /content/lama\n","!git clone -q https://github.com/advimman/lama.git /content/lama  # You can keep this if you want other lama utils\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vurDhKz68SAk","executionInfo":{"status":"ok","timestamp":1748708317043,"user_tz":-180,"elapsed":13395,"user":{"displayName":"amir grossman","userId":"06724055557739225239"}},"outputId":"cc30130c-f96b-4d24-bd66-9a49d19ccdd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# ⚡️ Step 1: Load Libraries\n","import os\n","import sys\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","import torch\n","from PIL import Image\n","\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2 import model_zoo\n","\n","from simple_lama_inpainting import SimpleLama"],"metadata":{"id":"qWGt87x18gLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBZ5kCbcpWAy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748708327972,"user_tz":-180,"elapsed":3160,"user":{"displayName":"amir grossman","userId":"06724055557739225239"}},"outputId":"3c0d4c66-9fed-4388-c57e-317c282cabbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["# Step 2: Setup Detectron2\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","\n","# Set device dynamically\n","cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {cfg.MODEL.DEVICE}\")\n","\n","predictor = DefaultPredictor(cfg)\n"]},{"cell_type":"code","source":["# Step 3: Setup SimpleLama model\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","lama_model = SimpleLama(device=device)"],"metadata":{"id":"ivSrP_eC07dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_ICFRkrpWH2"},"outputs":[],"source":["# Step 4: Load images from /content/images\n","# image_dir = \"/content/images\"\n","image_dir = \"/content/all_images\"\n","os.makedirs(image_dir, exist_ok=True)\n","image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.webp'))]\n","image_paths = sorted(image_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsR9iXI3pV7G","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1A3VSL_11-9B7A9IhSB5vxfThHbO_5Z9V"},"executionInfo":{"status":"ok","timestamp":1748709883504,"user_tz":-180,"elapsed":524507,"user":{"displayName":"amir grossman","userId":"06724055557739225239"}},"outputId":"72fde950-4c17-4ac5-c729-0e66789c609d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Step 5: Process images\n","for path in image_paths:\n","    image = cv2.imread(path)\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Detect people masks\n","    outputs = predictor(image_rgb)\n","    instances = outputs[\"instances\"]\n","    person_mask = np.zeros(image.shape[:2], dtype=bool)\n","    for i, cls in enumerate(instances.pred_classes):\n","        if cls.item() == 0:  # class 0 is person\n","            mask = instances.pred_masks[i].cpu().numpy()\n","            person_mask = np.logical_or(person_mask, mask)\n","\n","    person_mask_uint8 = (person_mask * 255).astype(np.uint8)\n","    kernel = np.ones((15, 15), np.uint8)  # change to image-size relative sizing?\n","    person_mask_dilated = cv2.dilate(person_mask_uint8, kernel, iterations=1)\n","\n","    # Inpaint with SimpleLama\n","    inpainted = lama_model(image_rgb, person_mask_dilated)\n","\n","    # Display results\n","    fig, axes = plt.subplots(1, 2, figsize=(12,6))\n","    axes[0].imshow(image_rgb)\n","    axes[0].set_title(\"Original\")\n","    axes[0].axis('off')\n","\n","    axes[1].imshow(inpainted)\n","    axes[1].set_title(\"People Removed\")\n","    axes[1].axis('off')\n","\n","    plt.show()\n","\n","    plt.figure(figsize=(6, 6))\n","    plt.imshow(person_mask_dilated, cmap='gray')\n","    plt.title(\"Person Mask\")\n","    plt.axis('off')\n","    plt.show()\n"]},{"cell_type":"markdown","source":["TODO:\n","* Dynamic dilate kernel size (drawing form image size)\n","* Think about shadowing and abstractions\n"],"metadata":{"id":"mE0638PbL68O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4d841fba"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNug9FiqDNa5LAE3WcTQVsN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}